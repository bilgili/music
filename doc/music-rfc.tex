\documentclass[a4paper]{report}

\usepackage[utf8]{inputenc}
\usepackage{fancyhdr}
\usepackage{color}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{makeidx}

%%%%% Formatting %%%%%

% Use the metatext environment around text that should not appear in
% the final document
\newenvironment{metatext}%
{\color{blue}}%
{}


% Use the rationale environment around arguments for design decisions
\newenvironment{rationale}%
{\par\paragraph{Rationale:}}%
{\par}


% Use the head environment around method heads
\lstnewenvironment{head}%
{\lstset{frame=lines}}%
{}


% Use the code environment around method code examples
\lstnewenvironment{code}%
{}%
{}


% Use the responsible command to indicate which author is responsible
% for the present section
\newcommand{\responsible}[1]%
{{\color{red}[#1 is responsible for this section]}}


% Use the irresponsible command to indicate which author is generally
% irresponsible
\newcommand{\irresponsible}[1]%
{{\color{red}[#1 is an irresponsible author]}}


\pagestyle{fancy}
\makeindex

%%%%% Actual content starts here %%%%%
\begin{document}

\lstset{language=C++}

\title{MUSIC --- Multi-Simulation Coordinator\\
  Provisional Specification}

\author{Örjan Ekeberg and Mikael Djurfeldt}

\maketitle

\begin{abstract}
  MUSIC is an API allowing large scale neuron simulators using MPI
  internally to exchange data during runtime.  MUSIC provides
  mechanisms to transfer massive amounts of event information and
  continuous values from one parallel application to another.  Special
  care has been taken to ensure that existing simulators can be
  adapted to MUSIC.  In particular, MUSIC handles data transfer
  between applications that use different time steps and different
  data allocation strategies.
\end{abstract}


\tableofcontents

\chapter{Introduction}

\responsible{Örjan}

\section{Scope}

MUSIC is a standard for run-time exchange of data between parallel
applications in a cluster environment.  The standard is designed
specifically for interconnecting large scale neuronal network
simulators, either with each-other or with other tools.


\section{Design Goals}

\subsection{Portability}

The MUSIC library and support software have been designed to run
smoothly on state-of-the-art high-performance hardware.  For maximal
portability, the software is written in C++, which is the
defacto-standard for current high-end hardware.  MUSIC also provides a
pure C-interface, making it possible for applications written i C or
FORTRAN to participate in a MUSIC multi-simulation.

Most, if not all, current efforts in large scale neuronal simulations
are based on the MPI\index{MPI} standard.  MUSIC is built on top of
MPI, and uses it to run the different simulators.  MPI encapsulates
software optimizations for specific hardware, and by basing the
interface on MPI we can benefit from such optimizations.  In
addition, MUSIC provides means to allow each simulator to use MPI
internally without interfering with the others.

During the development of MUSIC we have used two reference platforms:
Intel-based multi-core workstations and the IBM
BlueGene/L\index{BlueGene/L}\index{IBM BlueGene} supercomputer.  These
platforms can be considered as two extremes, where the multi-core
machine represents a small parallel environment while the BlueGene/L
represents a large scale parallel supercomputer with special
requirements.  In particular, the compute nodes on the BlueGene/L do
not support multiple threads or processes.


\subsection{Simplicity}

For MUSIC to be useful, it must be possible to adapt existing
simulators so that they can participate in a multi-simulation without
too much effort.  We rely on the simulator developers to make these
adaptations.  An important design goal has therefore been to adapt the
design to the typical structure of current simulators.  It should be
possible to add usage of the MUSIC library without invasive
restructuring of the existing simulator.

The requirements on an application using MUSIC is primarily that it,
during the setup phase, declares what data should be exported and
imported, and that it repeatedly calls a function at regular intervals
during the simulation to allow MUSIC to make the actual data transfer.


\subsection{Independence}

The MUSIC interface ensures that each individual application does not
need special adaptation to specific properties of other applications.
The application only needs to adhere to the specification of the MUSIC
interface in order to communicate with other applications performing
complementary tasks.  This makes the development of MUSIC-aware
software independent of what other applications it will communicate
with.

We hope that this will facilitate the development of general purpose
tools.  For example, a researcher can develop a tool for calculating
synthetic EEG from simulation data.  Via MUSIC, this tool should then
be useful for anybody using any neuronal simulator which supports the
common MUSIC interface.


\section{Terminology}

\begin{description}
\item[application] We use the term
  \emph{application}\index{application} to denote a simulator or other
  program interfaced to MUSIC.  Each application is a parallel
  program, normally running on several processors.

\item[port] Each application declares its ability to produce and
  consume data by publishing \emph{ports}\index{port}.  Ports are
  named by the application along with information about the datatype
  and mapping onto different processors.  Ports are either
  \verb|input_ports|\index{input port} or
  \verb|output_ports|\index{output port}.

\item[connection] During the setup phase, MUSIC connects pairs of
  ports together to form \emph{connections}\index{connection}.  During
  the runtime phase, data is transferred over the connection from the
  producer of the data to the consumer.

\item[map] Map\index{map} is a data structure used to keep track of
  the layout of data within an application.  Data to be transferred
  over a connection can be regarded as a large array distributed over
  multiple processors.  The map contains information about which
  processor has each element of data, and where the element is stored.

\item[ticks] During the runtime phase, all processes in each
  application must make a \emph{tick}\index{tick} call at regular
  intervals in simulated time.  At these tick points, MUSIC is allowed
  to use MPI to transfer the data between processors.
\end{description}


\section{Relation to Existing Software}

MUSIC is not the only software project aiming to support the
inter-operability between neural simulators.  In this section we will
briefly describe some related projects and specifically focus on how
they relate to MUSIC.

\paragraph{PyNN}\index{PyNN}

\paragraph{Neurospaces}\index{Neurospaces}

\paragraph{Neosim}\index{Neusim}


\chapter{Execution model}

\section{Phases of execution}

A multi-simulation, i.e. a set of interconnected parallel
applications, is executed in a few distinct phases:
\begin{enumerate}
\item \emph{Launch} is the phase where all the applications are
  started on the processors.  This has to be done before MPI is
  initialized and therefore has to be handled separately for different
  MPI implementations.
\item \emph{Setup} is the phase when all applications must publish
  what ports they are interested in, the time step they will use, and
  where data will be present (where in memory and/or on what processor).
\item \emph{Runtime} is the phase then simulation data are actually
  transferred.  Via the tick calls the simulated time of the
  applications are kept in order.
\end{enumerate}

As can be seen from section \ref{sec:responsibilities}, a MUSIC job
has three phases of execution:
\begin{enumerate}
  \item \textbf{Launch} is concerned with distributing and launching
    the application set within the set of MPI processes allocated to
    the MUSIC job.  The launch phase begins when mpirun launches the
    MUSIC binary and ends when the setup object constructor returns.
  \item \textbf{Setup} is concerned with the creation of ports and
    setting of parameters.  The setup phase begins when the setup
    object has been created and ends when the runtime object
    constructor returns.
  \item \textbf{Runtime} is the phase where simulation data is passed
    around between participating applications.  The runtime phase
    begins when the runtime object has been created and ends when the
    runtime method \verb|finalize| is called.
\end{enumerate}

\section{Concepts}

The \verb|index_map| maps indices local to the MPI process to global
indices within the distributed data array.  That is, the
\verb|index_map| tells which parts of a distributed data array are
handled by the local process and how the data elements are locally
ordered.

\section{Spatial distribution of data}
\responsible{Mikael}

Consider a connection between two ports.  Both the output and input
connectors can have arbitrary ordering of data.  How do output and
input connectors know the rank

\section{Timing considerations}
\responsible{Örjan}

Different applications may use different time steps and it is the
responsibility of MUSIC to ensure that data is delivered at the
appropriate time.  In order to minimize handshaking, both parts of a
connection pair locally calculate when the actual data transfer over
MPI takes place.  To ensure that these calculations produce
predictable results, simulation time is represented using integers
with a global micro-timestep common for all applications.

Simulation time is a state variable local for each application and
MUSIC does not enforce unnecessary synchronization between these local
clocks.  Thus, an application producing data may be running ahead of
another application which consumes the same data.  MUSIC internally
builds a schedule which ensures that data arrives at the appropriate
local time in the receiving application.  Scheduling becomes more
complex when data is not only transferred in a feed-forward manner,
i.e. the connection graph contains loops.  In this case MUSIC has to
rely on the existence of sufficient delays in the simulated model,
typically corresponding to axonal delays.


\section{Responsibilities of an application using MUSIC}

\chapter{Using MUSIC}

\subsection{The MUSIC configuration file}

\section{Launch}

We will have to provide tools for starting the simulators.  This
procedure will also take care of initializing communication between
processes.  Since most simulators will use parallel processing also
internally, it is necessary for the simulator to rely in the interface
for some of its own initialization too.  The tools should therefore be
useful for running simulators even in situations when only one
simulator is running.

\begin{metatext}
  MPI-2 comes with a program mpiexec which is capable of starting
  multiple applications directly.  In MPI-1 one can achieve the same
  result by starting a small "launcher" program which uses execve to
  start the real applications.  We should be able to write our interface
  so that it works in both situations.
\end{metatext}

\chapter{Application Program Interface}

\section{Setup}
\responsible{Mikael}

\subsection{The setup constructor}

The setup constructor creates the setup object through which
Each application will have to call an initialization routine in the API
which in turn initializes MPI.

\begin{head}
  setup::setup (int\& argc, char**\& argv)
\end{head}

This constructor must be called at most once; subsequent calls are
erroneous.  It accepts the \verb|argc| and \verb|argv| that are
provided by the arguments to \verb|main|:

\begin{code}
int main (int argc, char *argv[])
{
  MUSIC::setup* setup = new MUSIC::setup (argc, argv);

  /* parse arguments */
  /* rest of program */
}
\end{code}

\subsection{Communicators}

One communicator for each application, given to the application from
the API.

We should probably use the global communicator for all
inter-application communication.

\begin{metatext}
  \paragraph{Consideration:} Check if there are any advantages of having one
  separate communicator for each connection.
\end{metatext}

\begin{head}
    MPI::Intracomm communicator ();
\end{head}

\begin{code}
  /* Add example here */
\end{code}

\subsection{Port creation}

Ports have two stages in life: the \emph{empty} stage and the
\emph{mapped} stage.  A port is empty when created.  The MUSIC
configuration file specifies connections between ports.  It is
possible to ask an empty port if it is connected, if it has a
specified size and what size it has if this size is specified.

A port becomes mapped when its method \verb|map| is called with a
datamap.

\begin{head}
    cont\_input\_port* publish\_input (string identifier, cont\_data* map);

    cont\_output\_port* publish\_output (string identifier, cont\_data* map);

    event\_input\_port* publish\_input (string identifier, event\_data* map);

    event\_output\_port* publish\_output (string identifier, event\_data* map);
\end{head}

\begin{code}
  /* Add example here */
\end{code}

\subsection{Using ports}

\begin{head}
\verb|port::is_connected ()|
\end{head}

\begin{code}
  /* Add example here */
\end{code}

\subsection{Configuration variables}

\begin{head}
    bool config (string var, string* result);

    bool config (string var, int* result);

    bool config (string var, double* result);
\end{head}

\begin{code}
  /* Add example here */
\end{code}

\section{Runtime}

\subsection{tick ()}

Called in the local simulation loop of each application.
The interface may, or may not, exchange data with other applications
at the tick call.

The application must ensure that exported data values are valid when
tick() is called.  It must also expect that imported values may change.

The tick() should be called at regular intervals in simulation time.
The application chooses the interval, normally based on the time step
used in the application.  The interface must handle that different
applications can use different tick-intervals.


\subsection{Aliasing}

\begin{figure}
  \begin{center}
    \begin{minipage}{0.45\textwidth}
      \includegraphics[width=\textwidth]{figures/ticklogic}
      \caption{Transfer of data when sender has a shorter
        tick interval then the receiver}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
      \includegraphics[width=\textwidth]{figures/ticklogic2}
      \caption{Transfer of data when sender has a longer
        tick interval then the receiver}
    \end{minipage}
  \end{center}
\end{figure}

The interface should take care of spatial and temporal aliasing, that
is, to interpolate in space and time when the space and time steps of
two applications do not match.

To minimize communication, we always want to do the conversion on the
side which has the most dense data.

\paragraph{Motivation:} The application or model should not have to be
adapted to the steps used in other applications.


\subsubsection{Filters on sender side}

When the receiver of a data-flow has a longer tick-interval than the
receiver, then filters can be engaged to compress, smoothen, average,
or otherwise aggregate the data before transmission.

\begin{rationale}
  Filtering is needed on the sender side.  If we connect an existing
  simulation with a receiver with longer time step, we don't want to
  rewrite the simulation code to perform filtering.  Thus, the
  interface must support filtering.
\end{rationale}


\subsubsection{Interpolation on receiver side}

Needed when sender is slower than receiver.

Note that to make it possible to do interpolation, the sender has to
produce the next value before the receiver can enter the intermediate
time interval.  This needs careful scheduling of the transmissions to
avoid dead-lock situations.

\chapter{A complete example}

\chapter{Adapting existing software to MUSIC}

\chapter{Notes}

\section{Data structures}

\begin{description}
  \item[setup] Used to ask for configuration information and create
    ports.
  \item[runtime] Used during simulation.  Provides the \verb|tick ()|
    method.
  \item[port] A \verb|port| is the interface used to send or receive
    data from other applications.  It can be distributed over many MPI
    processes.  A port contains a \verb|datamap|.  There are
    \verb|output_port|s and \verb|input_port|s.
  \item[connector] An internal datastructure which represents the
    sending or receiving end of a connection between two ports.  An
    \verb|output_port| can have multiple connectors while an
    \verb|input_port| can have only one.
  \item[data\_map] Defines the data to be communicated through the
    port.  A data\_map consists of a pointer to the memory location
    containing the data (for continuous-valued data) and an
    index\_map.
  \item[index\_map] Defines which global indices are handled in the
    local MPI process and how they are organized in memory.
\end{description}

\subsection{Ports}

\subsection{Connectors}

A connector has at least the following components:
\begin{itemize}
  \item an inter-communicator
  \item a buffer for continuous data
  \item a remap strategy
\end{itemize}

A connector does \emph{not} support re-computation of spike time
stamps, i.e., it does not provide axonal delays.  Instead, it is
recommended that the receiver takes care of such delays.

A connected pair of an output connector and an input connector
constitutes a MUSIC \emph{connection}.

\subsection{Data maps}

\subsection{Index maps}

\verb|linear_map| can be implemented in terms of
\verb|permutation_map| which is the most general form of index map.

\section{The MUSIC application}

\subsection{Responsibilities visavi the MUSIC library}
\label{sec:responsibilities}

An application creates a \verb|setup| object.  \verb|argc| and
\verb|argv| are passed by reference to the \verb|setup| constructor
which may modify these variables.  The setup constructor calls
MPI:Init for the application.

\begin{rationale}
  The idea here is to replace the call to MPI:Init with a call to the
  setup constructor.  This way, it is not possible to forget to call
  an extra initialization routine.
\end{rationale}

The setup object is then used to query about configuration
information, to get the local communicator, and to create ports.

There should be no need to link an application differently when it is
used together with other applications in a MUSIC setting compared to
when it is used in a stand-alone setting.  In order to support
``standard'' operation for the application,
\verb|setup::communicator ()|, therefore, will return MPI::COMM\_WORLD
if the job is started directly with \verb|mpirun| instead of with the
MUSIC launcher.

Calling \verb|setup::done ()| will implicitly call the \verb|runtime|
object constructor.

During simulation, the application should repeatedly call
\verb|runtime::tick ()|.  This is typically done at each simulation
time step.

\section{Timing considerations}

During a MUSIC simulation data is communicated between two connectors
by pairwise blocking communication.  Both sends and receives occur
within a \verb|tick ()| call.

\subsection{Global clock}

Connector pairs do not necessarily communicate at every tick.  It is
therefore important that both sender and receiver know when to
communicate.  In order to determine this deterministically MUSIC uses
an internal global integer clock.  Application specific tick intervals
are translated to an integral number of global clock time steps using
the MUSIC \emph{timebase}.  The timebase can be specified in the
configuration file using the variable name ``timebase''.  The default
value is 1 ns.

The reference implementation uses a 64-bit integer to represent the
global clock.

\begin{rationale}
  \emph{Discuss indeterminacy of floating-point arithmetic, in particular
    with regard to re-ordering of arithmetic operations by the compiler.}
\end{rationale}

\subsection{Time zone difference}

Minimal latency

\subsection{Communication schedule}

The order of calls to \verb|MPI::Send| and \verb|MPI::Receive| within
output and input connectors can be important.  Consider two
connections between the same pair of applications.  If application 1
sends on output connectors A and B in sequence, within the same tick,
while application 2 receives on the corresponding input connectors in
reverse order (B, A) there will be a dead-lock.

Such dead-lock:s are avoided by imposing a fixed pairwise
communication schedule.  The setup phase creates and sorts output and
input connectors into a vector according to this schedule.  This
vector is passed to the runtime object.  At each \verb|tick ()|, the
runtime object iterates through the vector, giving each connector an
opportunity to communicate.

\subsection{Initialization}

Before calling \verb|setup::done ()| at the end of the setup phase,
the user must initialize all data associated to output ports through
datamap:s.  During \verb|setup::done ()|, this data is transferred to
all input ports.  This is so that data can subsequently be correctly
interpolated.

\appendix

\chapter{C interface}

\chapter{Specification file syntax}

\newcommand{\nt}[1]{$<$#1$>$}

\begin{tabular}{lcl}
\nt{simulation spec}   & ::= & \{ \nt{application block} \} \\
\nt{application block} & ::= & \nt{newline} '[' \nt{application id} ']' \{ \nt{declaration}
\} \\
\nt{application id}    & ::= & \nt{symbol} \\
\nt{declaration}       & ::= & \nt{variable def} $|$ \nt{connection} \\
\nt{variable def}      & ::= & \nt{variable} '=' \nt{value} \\
\nt{variable}	       & ::= & \nt{symbol} \\
\nt{value} 	       & ::= & \nt{integer} $|$ \nt{float} $|$ \nt{string} \\
\nt{connection}	       & ::= & \nt{port id} \nt{direction} \nt{port id} [ \nt{size} ] \\
\nt{port id}	       & ::= & \nt{application id} '.' \nt{port} $|$
\nt{port} \\
\nt{port}	       & ::= & \nt{symbol} \\
\nt{direction}	       & ::= & $->$ $|$ $<-$ \\
\nt{size}	       & ::= & '[' \nt{integer} ']' \\
\end{tabular}

\printindex

\end{document}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% eval: (flyspell-mode 1)
%%% eval: (ispell-change-dictionary "american")
%%% eval: (flyspell-buffer)
%%% End: 
