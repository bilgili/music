\documentclass[a4paper]{report}

\usepackage[utf8]{inputenc}
\usepackage{fancyhdr}
\usepackage{color}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{makeidx}
\usepackage{comment}

%%%%% Formatting %%%%%

% Use the metatext environment around text that should not appear in
% the final document
%\newenvironment{metatext}%
%{\color{blue}}%
%{}
\excludecomment{metatext}

% Use the rationale environment around arguments for design decisions
\newenvironment{rationale}%
{\par\paragraph{Rationale:}}%
{\par}


% Use the head environment around method heads
\lstnewenvironment{head}[1]%
{\lstset{frame=topline,emph={#1},emphstyle=\color{blue}\textbf}}%
{}


% Use the parameters environment after heads
\newenvironment{parameters}%
{\begin{tabular}{@{\hspace{2em}}lp{0.6\textwidth}}}%
{\end{tabular}\par\vspace{1mm}\par\hrule\par\vspace{5mm}}


% Use the code environment around method code examples
\lstnewenvironment{code}[1]%
{\lstset{frame=single,caption={#1}}}%
{}

\renewcommand{\lstlistingname}{Example}

% Use the responsible command to indicate which author is responsible
% for the present section
\newcommand{\responsible}[1]%
{{\color{red}[#1 is responsible for this section]}}


% Use the irresponsible command to indicate which author is generally
% irresponsible
\newcommand{\irresponsible}[1]%
{{\color{red}[#1 is an irresponsible author]}}

\fancyhead{}
\fancyhead[L]{\slshape\leftmark}

\pagestyle{fancy}
\makeindex

%%%%% Actual content starts here %%%%%
\begin{document}

\lstset{language=C++}

\title{MUSIC --- Multi-Simulation Coordinator\\[2ex]
  Request For Comments\\}

\author{Ã–rjan Ekeberg and Mikael Djurfeldt}

\maketitle

\begin{abstract}
  MUSIC is an API allowing large scale neuron simulators using MPI
  internally to exchange data during runtime.  MUSIC provides
  mechanisms to transfer massive amounts of event information and
  continuous values from one parallel application to another.  Special
  care has been taken to ensure that existing simulators can be
  adapted to MUSIC.  In particular, MUSIC handles data transfer
  between applications that use different time steps and different
  data allocation strategies.
\end{abstract}


\tableofcontents

\listoffigures

\chapter{Introduction}

This document constitutes a preliminary specification for the
multi-simulation coordinator MUSIC.  The main purpose of the current
document is to make it possible for potential users of MUSIC to
comment on the design before the full implementation is finalized.

\section{Scope}

MUSIC is a standard for run-time exchange of data between parallel
applications in a cluster environment.  The standard is designed
specifically for interconnecting large scale neuronal network
simulators, either with each-other or with other tools.

A typical usage case is illustrated in figure~\ref{fig:multisim},
where three applications ($A$, $B$, and $C$) are executing in parallel
while exchanging data via MUSIC.  We will refer to this as a
\emph{multi-simulation}, since the participating applications
typically are neuronal simulators, or tools to support such
simulators.  In this example, application $A$ produces runtime data
which is then used by $B$ and $C$.  In addition, $B$ and $C$ mutually
send data to each other.  The data sent between applications can be
either event based, such as neuronal spikes, or graded continuous
values, for example membrane voltages.

\begin{figure}
  \begin{center}
    \includegraphics[width=0.5\textwidth]{figures/multisim}
    \caption[Typical multi-simulation]{\label{fig:multisim}
      Illustration of a typical multi-simulation using MUSIC.  Three
      applications, $A$, $B$, and $C$, are exchanging data during
      runtime.
    }
  \end{center}
\end{figure}

The primary objective of MUSIC is to support multi-simulations where
each participating application itself is a parallel simulator with the
capacity to produce and/or consume massive amounts of data.  This
promotes \emph{inter-operability} by allowing models written for
different simulators to be simulated together in a larger system.  It
also enables \emph{re-usability} of models or tools by providing a
standard interface.  The fact that data is spread out over a number of
processors makes it non-trivial to coordinate the transfer of data so
that it reaches the right destination at the right time.  The task for
MUSIC is to relieve the applications from handling this complexity.


\section{Design Goals}

\subsection{Portability}

The MUSIC library and support software have been designed to run
smoothly on state-of-the-art high-performance hardware.  For maximal
portability, the software is written in C++, which is the
de facto standard for current high-end hardware.  MUSIC also provides a
pure C-interface, making it possible for applications written i C or
FORTRAN to participate in a MUSIC multi-simulation.

Most, if not all, current efforts in large scale neuronal simulations
are based on the MPI\index{MPI} standard.  MUSIC is built on top of
MPI, and uses it to run the different simulators.  MPI encapsulates
software optimizations for specific hardware, and by basing the
interface on MPI we can benefit from such optimizations.  In
addition, MUSIC provides means to allow each simulator to use MPI
internally without interfering with the others.

During the development of MUSIC we have used two reference platforms:
Intel-based multi-core workstations and the IBM
BlueGene/L\index{BlueGene/L}\index{IBM BlueGene} supercomputer.  These
platforms can be considered as two extremes, where the multi-core
machine represents a small parallel environment while the BlueGene/L
represents a large scale parallel supercomputer with special
requirements.  In particular, the compute nodes on the BlueGene/L do
not support multiple threads or processes.


\subsection{Simplicity}

For MUSIC to be useful, it must be possible to adapt existing
simulators so that they can participate in a multi-simulation without
too much effort.  We rely on the simulator developers to make these
adaptations.  An important design goal has therefore been to adapt the
design to the typical structure of current simulators.  It should be
possible to add usage of the MUSIC library without invasive
restructuring of the existing simulator.

The requirements on an application using MUSIC is primarily that it,
during the setup phase, declares what data should be exported and
imported, and that it repeatedly calls a function at regular intervals
during the simulation to allow MUSIC to make the actual data transfer.


\subsection{Independence}

The MUSIC interface ensures that each individual application does not
need special adaptation to specific properties of other applications.
The application only needs to adhere to the specification of the MUSIC
interface in order to communicate with other applications performing
complementary tasks.  This makes the development of MUSIC-aware
software independent of what other applications it will communicate
with.

We hope that this will facilitate the development of general purpose
tools.  For example, a researcher can develop a tool for calculating
synthetic EEG from simulation data.  Via MUSIC, this tool should then
be useful for anybody using any neuronal simulator which supports the
common MUSIC interface.


\section{Terminology}

\begin{description}
\item[application] We use the term
  \emph{application}\index{application} to denote a simulator or other
  program interfaced to MUSIC.  Each application is a parallel
  program, normally running on several processors.

\item[multi-simulation] We use the term
  \emph{multi-simulation}\index{multi-simulation} to refer to the
  whole parallel execution of multiple applications coordinated by
  MUSIC.

\item[port] Each application declares its ability to produce and
  consume data by publishing \emph{ports}\index{port}.  Ports are
  named by the application along with information about the datatype
  and mapping onto different processors.  Ports are either
  \lstinline|input_ports|\index{input port} or
  \lstinline|output_ports|\index{output port}.

\item[connection] During the setup phase, MUSIC connects pairs of
  ports together to form \emph{connections}\index{connection}.  During
  the runtime phase, data is transferred over the connection from the
  producer of the data to the consumer.

\item[data map] A data map\index{data map} denotes the information on
  where data actually resides within the application.  This is
  typically stored internally in the port data structure.  Data to be
  transferred over a connection can be regarded as a large array
  distributed over multiple processors, and the data map can tell on
  what processor each data element resides and how it should be
  accessed.

\item[ticks] During the runtime phase, all processes in each
  application must make a \emph{tick}\index{tick} call at regular
  intervals in simulated time.  At these tick points, MUSIC is allowed
  to use MPI to transfer the data between processors.
\end{description}


\section{Relation to Existing Software}

MUSIC is not the only software project aiming to support the
inter-operability between neural simulators.  In this section we will
briefly describe some related projects and specifically focus on how
they relate to MUSIC.

\paragraph{PyNN}\index{PyNN}

PyNN is a Python package for simulator-independent specification of
neuronal network models.  It provides a low-level procedural API and a
high-level object-oriented API.  Neuronal network models which are
specified using these API:s can be simulated on simulators supporting
PyNN, such as Neuron and NEST.

PyNN could be extended to support multi-simulations using the MUSIC
library.  Such an extension would provides means for controlling the
interaction between the simulator and the MUSIC library and would, for
example, support publishing of named ports.

It is possible, in principle, to write Python code to directly handle
communication between applications in a cluster, but such a solution
would be inefficient compared to using MUSIC, and might, in the end,
have to address the same problems which MUSIC provides a solution to.

\paragraph{Neurospaces}\index{Neurospaces}

The Neurospaces project promotes inter-operability and re-usability
through the development of independent software components, some of
which, together, will provide one of two alternative cores of the
Genesis 3 simulator.  One of the components, the Neurospaces Model
Container abstracts model description from the solver.  Another
component, the Discrete Event System can handle distribution and
queuing of spikes.  Components adhere to the CBI simulator
architecture.

It is possible to develop a MUSIC adapter consistent with the CBI
simulator architecture.  This would allow the Neurospaces framework,
and Genesis 3, to interface to independently running applications in a
cluster environemnt.

\begin{metatext}
\paragraph{Neosim}\index{Neosim}

\paragraph{MOOSE}\index{MOOSE}
\end{metatext}

\chapter{Execution Model}

\section{Phases of Execution}

A multi-simulation, i.e. a set of interconnected parallel
applications, is executed in three distinct phases:
\begin{description}
\item[\textbf{Launch}]\index{launch phase} is the phase where all the
  applications are started on the processors.  During this phase,
  MUSIC is responsible for distributing and launching the application
  binaries on the set of MPI processes allocated to the MUSIC job.
  This has to be done before MPI is initialized and therefore has to
  be handled separately for different MPI implementations.

  Technically, the launch phase begins when \texttt{mpirun} launches
  the MUSIC binary and ends when the setup object constructor returns.

\item[\textbf{Setup}]\index{setup phase} is the phase when all
  applications can publish what ports they are prepared to handle
  along with the time step they will use and where data will be
  present (where in memory and/or on what processor).  During the
  setup phase, the applications can read configuration parameters
  communicated via the common configuration file.  At the end of the
  setup phase, MUSIC will establish all connections.

  The setup phase begins when the setup object has been created and
  ends when the runtime object constructor returns.

\item[\textbf{Runtime}]\index{runtime phase} is the phase then
  simulation data is actually transferred between applications.  Via
  the \texttt{tick} calls the simulated time of the applications is
  kept in order.

  The runtime phase begins when the runtime object has been created
  and ends when the runtime object is destroyed.
\end{description}

From the application programmers point of view, these phases are
clearly separated through the use of the two main components of the
MUSIC interface: the \emph{setup} and the \emph{runtime} object.  The
launch phase is not visible for the application since it handles the
situation before the application starts.

When the application initializes MUSIC at the beginning of execution
it receives a specific \emph{setup object}.  This object gives access
to the functionality relevant during the setup phase via its methods.
When done with the setup, the application program makes the transition
to the runtime phase by calling a method in the setup object which
destroys the setup object and returns a \emph{runtime object}.  This
runtime object provides methods relevant during the runtime phase of
execution.

\section{Spatial Distribution of Data}

Communication between applications is handled by ports.  Ports are
named sources (output ports) or sinks (input ports) of data flows.
The data to be communicated between the sender application and the
receiver may be differently organized in process memory, the
applications may run on different numbers of processes, and, the data
may be differently distributed among the sender processes and the
receiver processes, as is shown in Figure~\ref{fig:datamapping}.  How
does MUSIC know which data to send where?

In MUSIC, there are two views of the data to be communicated over a
connection.  Data elements are enumerated differently according to
these views.  MUSIC uses \emph{global indices}\index{global index} to
enumerate the entire set of data to be sent over the connection while
\emph{local indices}\index{local index} enumerate the subset of data
which is stored in the memory of a particular MPI process.  Data does
not need to be ordered in the same way according to the two views.
For example, local data stored in an array may be associated with an
arbitrary subset of global indices in an arbitrary order.

The MUSIC library is informed about the relationship between global
and local indices during the setup phase.  Two abstractions are used
to carry this information:

The \lstinline|index_map| maps indices local to global indices.  That
is, the \lstinline|index_map| tells which parts of a distributed data
array are handled by the local process and how the data elements are
locally ordered.

The \lstinline|data_map| encapsulates how a port accesses its data.
The \lstinline|data_map| contains an \lstinline|index_map|.  While an
index map is a mapping between two kinds of indices, the data map also
contains information about where in memory data resides, how it is
structured, and, the type of the data elements.

During setup every process of the application individually provides
the port with a \lstinline|data_map| (or an \lstinline|index_map| in
the case of event ports).

\begin{figure}
  \begin{center}
    \includegraphics[width=0.7\textwidth]{figures/datamapping}
    \caption[Mapping of data]{\label{fig:datamapping}
      Data transfer over a connection from an application running in
      four processes to an application running in three other.  The
      light gray areas in the sender and receiver represents the MUSIC
      port.  Dashed lines divide the application into distinct
      processes.
    }
  \end{center}
\end{figure}

\section{Timing Considerations}
\label{sec:timing}
  
Different applications may use different time steps and it is the
responsibility of MUSIC to ensure that data is delivered at the
appropriate time.  In order to minimize handshaking, both parts of a
connection pair locally calculate when the actual data transfer over
MPI takes place.  To ensure that these calculations produce
predictable results, simulation time is represented using integers
with a global micro-timestep\index{micro-timestep} common for all
applications.

Simulation time\index{simulation time} is local for each application
and MUSIC does not enforce unnecessary synchronization between these
local clocks.  Thus, an application producing data may be running
ahead of another application which consumes the same data.  MUSIC
internally builds a schedule which ensures that data arrives at the
appropriate local time in the receiving application.  Scheduling
becomes more complex when data is not only transferred in a
feed-forward manner, i.e. the connection graph contains loops.  In
this case MUSIC has to rely on the existence of sufficient delays in
the simulated model, typically corresponding to axonal
delays\index{axonal delay}.

\begin{figure}
  \begin{center}
    \begin{minipage}{0.45\textwidth}
      \includegraphics[width=\textwidth]{figures/ticklogic}
      \caption[Timing of data transfer, slowdown]{\label{fig:timingshorter}
        Transfer of data when sender has a shorter
        tick interval than the receiver}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
      \includegraphics[width=\textwidth]{figures/ticklogic2}
      \caption[Timing of data transfer, speedup]{\label{fig:timinglonger}
        Transfer of data when sender has a longer
        tick interval than the receiver}
    \end{minipage}
  \end{center}
\end{figure}

Figures~\ref{fig:timingshorter} and \ref{fig:timinglonger} illustrate
how MUSIC handles time when transferring continuous data over a connection.
In figure~\ref{fig:timingshorter}, the sender application uses a
shorter interval between the tick calls than the receiver.  The sender
side uses values sampled at the tick points to interpolate a value
corresponding to the point in time when the receiver makes its tick
call.

The dark middle area (labelled ``MPI'') is where the actual data
transfer takes place.  MUSIC makes use of the fact that the receiving
application can run with its simulation clock set independently of the
sender.  The arrows going ``backwards in time'' in this area reflect
the fact that the receivers clock is lagging.  This makes it possible
for data to arrive in time despite the fact that it was available
later than when it was arriving.

Figure~\ref{fig:timinglonger} illustrates what happens when the
receiver is calling tick faster then the sender.  The sender will then
have to buffer up multiple values to be transferred at a suitable tick
call, and the receiver will portion these values out at the
appropriate ticks.

The strategy of having the receiver application running with a delayed
local clock only works when the connection graph forms a directed
acyclic graph (DAG)\index{DAG}\index{acyclic graph}\index{loops}.
When loops occur it is necessary to allow for data arriving late, at
least somewhere along each loop.  MUSIC handles this via
\emph{acceptable latency}\index{acceptable latency}\index{latency}
which is a property of each input port.  The receiving application
declares how late data may arrive, thus giving MUSIC room for
resolving the scheduling problem.


\section{Application Responsibilities}

One goal of MUSIC has been to limit the responsibilities imposed on
each application.  Here we present a step-by-step list of what an
application must do in order to participate in a multi-simulation.

\begin{enumerate}
\item \textbf{Initiate MUSIC}\index{initiate MUSIC}

  This is done by calling the \lstinline!setup! function.
\item \textbf{Create ports}

  Data to be imported and exported is identified by creating named
  ports.
\item \textbf{Map ports}\index{map ports}

  MUSIC is informed about where the actual data is located.
  This includes information about which processor owns each data
  element.  For continuous data it also includes information about
  where in memory it is stored, while for event data it defines what
  functions to use to send and receive the events.
\item \textbf{Initiate the runtime phase}

  At this stage, MUSIC can build the plan for communication between
  different processes.
\item \textbf{Advance simulation time}\index{tick}\index{advance time}
  \index{time}

  The application must call \lstinline!tick ()! at regular intervals
  to give MUSIC the opportunity to transfer data.
\item \textbf{Finalize MUSIC}\index{finalize}\index{terminate}

  By deleting the runtime object, all MUSIC communication is terminated.
\end{enumerate}


\chapter{Starting a Multi-Simulation}

\section{Overview}

Parallel programs based on MPI are normally started by running a
special program called \texttt{mpirun}\index{mpirun} (for MPI-1) or
\texttt{mpiexec}\index{mpiexec} (for MPI-2).  To start multiple
applications and enable them to communicate with each other, MUSIC
utilizes a special launcher program called \texttt{music}\index{music}
which, in turn, starts the different applications.  Information about
which applications should be started, and the communication pattern
between them is described in a common \emph{configuration
  file}\index{configuration file}.


\section{The Configuration File}

The main purpose of the configuration file is to control what
applications to start, and to connect output ports to input ports.
The configuration file specifies the number of processors allocated to
each application.

The configuration file consists of a sequence of blocks, each starting
with a non-indented bracket:

\begin{quote}
  [\emph{application\_label}]
\end{quote}

\noindent Each block consists of a sequence of configuration variable
definitions applying to one application.  The application label is
used to refer to ports of the application.  A variable definition
takes the form of an assignment:

\begin{quote}
  \emph{varname} = \emph{value}
\end{quote}

The following variable names have special meaning to MUSIC:
\begin{description}
  \item[binary] Pathname to application binary
  \item[args] Command line given to the binary
  \item[np] The number of MPI processes to allocate for the application
  \item[timebase] The length of a MUSIC micro-step, that is, the
    resolution of MUSIC:s internal clocks).  (Default value is 1 ns.)
\end{description}
Arbitrarily named parameters may also be included in the configuration
file and these parameters can be accessed from the applications.

A connection between a sender and receiver port is specified using the
following syntax:
\begin{quote}
  \emph{application\_label.port\_name} \lstinline|->| \emph{application\_label.port\_name}
\end{quote}
\noindent.  The direction of the arrow (\lstinline|->|, \lstinline|<-|) indicates the
direction of data transport.
Optionally, the width of the connections between applications can be
specified:
\begin{quote}
  \emph{application\_label.port\_name} \lstinline|->|
  \emph{application\_label.port\_name} [\emph{width}]
\end{quote}
The application label can be omitted if it refers to the application
being specified by the surrounding block.
An example of a simple configuration file can be seen in
section~\ref{sec:conffile}.  Appendix~\ref{sec:specsyntax} specifies
the formal syntax of configuration files.


\chapter{Application Program Interface}

\section{Conventions}

This chapter describes the API to the MUSIC library.  The API is
object oriented and all communication with the library is performed
via instance methods of different classes of objects.  The most common
way of passing objects as arguments in MUSIC is via pointers.  The
only exception is the setup constructor.  The conventions are then
that it is the caller who should make sure that the object exists in
memory during the entire execution of the method, and it is the caller
who is responsible for the deallocation of the object afterwards.

\section{Error handling}
\responsible{Mikael}


\section{Setup}

\subsection{The setup constructor}

Each application initializes the MUSIC library through a call to the
setup constructor\index{setup}.  This constructor, in turn, calls
MPI::Init\index{MPI::Init}\index{init} to initialize
MPI\index{initialize MPI}.  The setup constructor creates the setup
object through which the application can retrieve configuration
information, get an application wide communicator, and setup ports.

\begin{head}{setup}
  setup::setup (int& argc, char**& argv)
\end{head}
\begin{parameters}
  \lstinline|argc| &%
  reference to the \lstinline|argc| argument of \lstinline|main| \\
  \lstinline|argv| &%
  reference to the \lstinline|argv| argument of \lstinline|main| \\
\end{parameters}

This constructor must be called at most once; subsequent calls are
erroneous.  It accepts the \lstinline|argc| and \lstinline|argv| that are
provided by the arguments to \lstinline|main|.

\pagebreak
\begin{code}{Initializing MUSIC}
int main (int argc, char *argv[])
{
  MUSIC::setup* setup = new MUSIC::setup (argc, argv);

  /* parse arguments */
  /* rest of program */
}
\end{code}

\subsection{Communicators}

During a multi-simulation, launched using the \lstinline|music|
utility command, the music library will create a unique
intra-communicator over the group of processes assigned to the
application.  This application wide communicator is retrieved from the
setup object through a call to the
\lstinline|communicator| method.\index{communicator}

\begin{head}{communicator}
  MPI::Intracomm setup::communicator ()
\end{head}
\begin{parameters}
  \emph{return value} & the application wide communicator \\
\end{parameters}

The application is supposed to use the application wide communicator
in place of
\lstinline|MPI::COMM_WORLD|\index{MPI::COMM\_WORLD}\index{COMM\_WORLD}.
This communicator can be used as any ordinary MPI communicator.

\begin{code}{Accessing the application-wide communicator}
/* communicator with global scope */
extern MPI_Comm comm;

...
{
  ...
  comm = setup->communicator ();
  int rank = comm.Get_rank ();
  ...
}
\end{code}

\pagebreak
\subsection{Port creation}

Ports\index{ports} are named sources (output ports) or sinks (input
ports) of data flows.  Output and input ports are distinct classes.
Ports are further subdivided into distinct classes depending on
whether they handle continuous or event data.

\index{publish\_output}\index{publish\_input}
\begin{head}{publish_output,publish_input}
  cont_output_port* setup::publish_cont_output (string id)

  cont_input_port* setup::publish_cont_input (string id)

  event_output_port* setup::publish_event_output (string id)

  event_input_port* setup::publish_event_input (string id)
\end{head}
\begin{parameters}
  \lstinline|id| & port name \\
  \emph{return value} & an empty port \\
\end{parameters}

Ports have two stages in life: the \emph{empty} stage and the
\emph{mapped} stage.  A port is empty when created.  The MUSIC
configuration file specifies connections between ports.  It is
possible to ask an empty port if it is connected, if it has a width
specified and, if so, what width it has.  A port becomes mapped when
its method \lstinline|map| is called with a \lstinline|data_map| (or
\lstinline|index_map| in the case of event ports).

\begin{code}{Creating an empty port}
cont_output_port* out =
   setup->publish_cont_output ("out");
\end{code}

\subsection{Port methods}

The port API includes methods to ask a port if it is connected, if it
has a specified width and what width it has if this width is
specified.  A port becomes mapped when its method \lstinline|map| is
called with a data map.

\subsubsection{Port connectivity}

The method \lstinline|is_connected| is used to check if the user has
specified a connection of this port to another port in the
configuration file.

\index{is\_connected}\index{connected port}
\begin{head}{is_connected}
  bool port::is_connected ()
\end{head}
\begin{parameters}
  \emph{return value} & \lstinline|true| only if connected\\
\end{parameters}

This method is typically used in cases where the use of some of the
ports of the application is optional.  In such a case, it is not
sensible to allocate any application resources to support the data
flow in question.  One example is if one wants to support output of
membrane potentials from a certain population of cells, but don't want
to waste resources if no one is listening.

\pagebreak
\begin{code}{Optional handling of ports}
cont_output_port* out =
   setup->publish_cont_output ("Vm");
/* map port only if anyone is listening */
if (out->is_connected ())
  /* allocate application resources and map port */
\end{code}

\subsubsection{Port width}
\label{sec:width}

The width of a port\index{port width}, that is the number of data
elements transferred in parallel from a cont port or the largest
possible id of an event port $+ 1$, can be specified in the
configuration file. This should be thought of as a request for a given
width.  Applications can use the method \lstinline|has_width| to
determine if a width has been specified and retrieve the width using
\lstinline|width|.

\index{has\_width}
\begin{head}{has_width}
  bool port::has_width ()
\end{head}
\begin{parameters}
  \emph{return value} & \lstinline|true| only if port width has been
                         specified \\
\end{parameters}

\index{width}
\begin{head}{width}
  int port::width ()
\end{head}
\begin{parameters}
  \emph{return value} & port width \\
\end{parameters}

Applications can use the above methods to adapt their port width.  See
example \ref{code:adaptivewidth}.

\subsubsection{Mapping a port}

A port is informed about what data exists locally and how to access it
by mapping it.

Cont ports transfer data from or to memory during \lstinline|tick ()|
calls and need to know the layout of data in memory.  This information
is captured by a data map:

\index{map}\index{mapping ports}
\begin{head}{map}
  void cont_output_port::map (cont_data* dmap)

  void cont_input_port::map (cont_data* dmap)
\end{head}
\begin{parameters}
  \lstinline|dmap| & the data map associated with the port \\
\end{parameters}

See section \ref{sec:datamap} below.

Since event ports don't access data the same way as cont ports, they
do not require a full \lstinline|data_map|.  Events are communicated
to the application through an \emph{event handler}\index{event
handler}.  The event handler is called by MUSIC when the application
calls \lstinline|tick|.  It is called once for every spike delivered.

\pagebreak
\begin{head}{map}
  class event_handler {
  public:
    virtual void operator () (double t, int id) = 0;
  };
  
  void event_output_port::map (index_map* indices)

  void event_input_port::map (index_map* indices,
                              event_handler* insert_event,
                              double acc_latency)
\end{head}
\begin{parameters}
  \lstinline|indices| & the index map associated with the port \\
  \lstinline|insert_event| & a user-defined event handler \\
  \lstinline|accept_latency| & acceptable latency for incoming data (s)
  \\
\end{parameters}

Some spiking neural network models include axonal delays.  The MUSIC
framework assumes that handling and delivery of delayed spikes occurs
on the receiver side.  In such a case, the receiver may allow MUSIC to
deliver a spike event later than its time stamp according to local
time.  The maximal acceptable latency is specified through the
\lstinline|accept_latency| argument.
  
\begin{rationale}
The current RFC only specifies acceptable latency for event input
ports only.  As discussed in section \ref{sec:timing} this allows for
applications to be connected in loops with regard to spiking
communication, while no loops are allowed with regard to continuous
data.
\end{rationale}

\begin{code}{Mapping ports to internal data\label{code:mapping}}
{
  ...
  int size = comm.Get_size ();
  int rank = comm.Get_rank ();
  /* for clarity we assume that n_elements
     is a multiple of size */
  int n_local = n_elements / size;
  double* state_vars = new double[n_local];
  MUSIC::cont_input_port* out =
     setup->publish_cont_output ("out");
  array_data dmap (state_vars, MPI::DOUBLE,
                   rank * n_local, n_local);
  out->map (&dmap);
  ...
}
\end{code}

Some applications, for example those who provide some kind of more
generic processing, like a visualization application, may want to be
able to accept input of any width.  This can be achieved using the
methods described in section \ref{sec:width}:

\pagebreak
\begin{code}{Publishing port of adaptive width\label{code:adaptivewidth}}
{
  ...
  /* Publishing a port of adaptive width */
  double* state_vars;
  MUSIC::cont_input_port* in =
     setup->publish_cont_input ("in");
  if (!in->has_width ())
    /* report error */
  else
    {
      int size = in->width ();
      /* for clarity we assume that n_elements
         is a multiple of size */
      int n_local = n_elements / size;
      /* example continues as above */
      ...
      
    }
}
\end{code}

\subsubsection{Sending events}

The sender registers an event for transmission by calling the method
\lstinline|insert_event|.

\index{insert\_event}
\begin{head}{insert_event}
  void event_output_port::insert_event (double t, int id)
\end{head}
\begin{parameters}
\end{parameters}

MUSIC guarantees that this event will be delivered through a call to
the user-specified \lstinline|event_handler| on the receiver side no
later that the acceptable latency relative to receiver local time.

\subsection{Index maps}
\index{index maps}

An index map is a mapping from local data element indices to
global. An index map instance thus holds information of which global
indices belong to the local MPI process and of their order with regard
to local index.  The most general form is the
\lstinline|permutation_index| which allows for an arbitrary mapping.

\index{permutation\_index}
\begin{head}{permutation_index}
  permutation_index::permutation_index (int* indices,
                                        int size)
\end{head}
\begin{parameters}
  \lstinline|indices| & vector of global indices \\
  \lstinline|size| & number of global indices \\
\end{parameters}

\index{linear\_index}
\begin{head}{linear_index}
  linear_index::linear_index (int baseindex, int size)
\end{head}
\begin{parameters}
  \lstinline|baseindex| & global index of first local element \\
  \lstinline|size| & number of contiguous global indices \\
\end{parameters}

When a cont output port is mapped it becomes associated with a set of
state variables (or other data) in the memory of the sender.  When the
receiver calls \lstinline|runtime::tick ()|, an estimate of the values
of these variables are stored in a set of variables associated with an
input port on the receiver side.  Similarly, an event output port is
mapped to a set of event id:s.

While the number of variables or id:s on the receiver side is always
the same as on the sender side, the data can be distributed in
different ways between MPI processes on the sender side compared to
the receiver side.  In fact, sender and receiver may consist of
different numbers of processes.

Index maps are used in each MPI process to tell MUSIC how data is
distributed and ordered by enumerating the global indices represented
by the process in local order.

\subsection{Data maps}
\label{sec:datamap}
\index{data maps}

A data map encapsulates how a port accesses its data.  While an index
map is a mapping between two kinds of indices, the data map also
contains information about where in memory data resides, how it is
structured, and, the type of the data elements.  One type of data map
is the array data map, which describes arrays of data elements.

\index{array\_data}
\begin{head}{array_data}
  array_data::array_data (void* buffer, MPI_Datatype type,
                          index_map* map)
\end{head}
\begin{parameters}
  \lstinline|buffer| & data memory location \\
  \lstinline|type|   & data type \\
  \lstinline|map|    & index map \\
\end{parameters}

Since array data is common, MUSIC provides a convenient form of the
array data map constructor which also creates an index map:

\begin{head}{array_data}
  array_data::array_data (void* buffer,
                          MPI_Datatype type,
                          int  baseindex,
                          int size)
\end{head}
\begin{parameters}
  \lstinline|buffer|    & data memory location \\
  \lstinline|baseindex| & global index of first local element \\
  \lstinline|size|      & number of contiguous global indices \\
\end{parameters}

See example \ref{code:mapping}.

\pagebreak
\subsection{Configuration variables}
\index{configuration variables}

The values of all variables defined in the configuration file can be
queried using the method \lstinline|config|.

\index{config}
\begin{head}{config}
  bool config (string var, string* result)

  bool config (string var, int* result)

  bool config (string var, double* result)
\end{head}
\begin{parameters}
  \lstinline|var|     & variable name \\
  \lstinline|result|  & pointer to location where result should go \\
  \emph{return value} & true if value of correct type was found \\
\end{parameters}

Querying after a value of type \lstinline|int| or \lstinline|double|
expects a value of the correct type, if defined in the configuration
file.  If the variable is defined, but its value can't be translated
into the correct type this causes an error condition.

\begin{code}{Querying configuration variables}
/* Retrieving the parameter gKCa
   from configuration file */
double gKCa;
if (!config ("gKCa", &gKCa))
  gKCa = 29.5e-9; // default value
\end{code}

\subsection{End of setup---creating the runtime object}

\begin{head}{done}
  runtime* setup::done (double h)
\end{head}
\begin{parameters}
  \lstinline|h| & simulated time elapsed between each \lstinline|tick ()| (s) \\
\end{parameters}

\section{Runtime}

\subsection{The \lstinline|tick ()|}
\index{tick}

Called in the local simulation loop of each application.  The
interface may, or may not, exchange data with other applications at
the tick call.

\begin{head}{tick}
  void runtime::tick ()
\end{head}
\begin{parameters}
\end{parameters}

The application must ensure that exported data values are valid when
tick() is called.  It must also expect that imported values may change.

The tick() should be called at regular intervals in simulation time.
The application chooses the interval, normally based on the time step
used in the application.  The interface must handle that different
applications can use different tick-intervals.

\pagebreak
\subsection{Simulation time}
\index{simulation time}

The method \lstinline|time ()| returns local time in seconds.

\index{time}
\begin{head}{time}
  double runtime::time ()
\end{head}
\begin{parameters}
  \emph{return value} & local time (s) \\
\end{parameters}

\lstinline|time ()| returns the local time of next \lstinline|tick ()|
call.  Time starts at 0 s.  While it is possible, and recommended, to
let MUSIC keep track of time for the application, this is not
required.

\subsection{Finalization}

\index{finalize}
\begin{head}{finalize}
  void runtime::finalize ()
\end{head}
\begin{parameters}
\end{parameters}

\chapter{A Complete Example}

This chapter shows a minimal but still complete example.  It consists
of two applications, \texttt{waveproducer} and \texttt{waveconsumer},
and a configuration file used to launch and connect them.


\section{Configuration File}
\label{sec:conffile}

The configuration file starts the waveproducer application on three
processors and waveconsumer on four.

\lstinputlisting[language=Clean,frame=single]{../test/wavetest.music}


\section{Data Generating Application}

\lstinputlisting{../test/waveproducer.cc}


\section{Data Consuming Application}

\lstinputlisting{../test/waveconsumer.cc}


\begin{metatext}
\chapter{Adapting Existing Software}
\end{metatext}

\begin{metatext}
\chapter{Notes}

\section{Data Structures}

\begin{description}
  \item[setup] Used to ask for configuration information and create
    ports.
  \item[runtime] Used during simulation.  Provides the \lstinline|tick ()|
    method.
  \item[port] A \lstinline|port| is the interface used to send or receive
    data from other applications.  It can be distributed over many MPI
    processes.  A port contains a \lstinline|datamap|.  There are
    \lstinline|output_port|s and \lstinline|input_port|s.
  \item[connector] An internal datastructure which represents the
    sending or receiving end of a connection between two ports.  An
    \lstinline|output_port| can have multiple connectors while an
    \lstinline|input_port| can have only one.
  \item[data\_map] Defines the data to be communicated through the
    port.  A data\_map consists of a pointer to the memory location
    containing the data (for continuous-valued data) and an
    index\_map.
  \item[index\_map] Defines which global indices are handled in the
    local MPI process and how they are organized in memory.
\end{description}

\subsection{Ports}

\subsection{Connectors}

A connector has at least the following components:
\begin{itemize}
  \item an inter-communicator
  \item a buffer for continuous data
  \item a remap strategy
\end{itemize}

A connector does \emph{not} support re-computation of spike time
stamps, i.e., it does not provide axonal delays.  Instead, it is
recommended that the receiver takes care of such delays.

A connected pair of an output connector and an input connector
constitutes a MUSIC \emph{connection}.

\subsection{Data maps}

\subsection{Index maps}

\lstinline|linear_map| can be implemented in terms of
\lstinline|permutation_map| which is the most general form of index map.

\section{The MUSIC application}

\subsection{Responsibilities visavi the MUSIC library}
\label{sec:responsibilities}

An application creates a \lstinline|setup| object.  \lstinline|argc|
and \lstinline|argv| are passed by reference to the \lstinline|setup|
constructor which may modify these variables.  The setup constructor
calls MPI:Init for the application.

\begin{rationale}
  The idea here is to replace the call to MPI:Init with a call to the
  setup constructor.  This way, it is not possible to forget to call
  an extra initialization routine.
\end{rationale}

The setup object is then used to query about configuration
information, to get the local communicator, and to create ports.

There should be no need to link an application differently when it is
used together with other applications in a MUSIC setting compared to
when it is used in a stand-alone setting.  In order to support
``standard'' operation for the application,
\lstinline|setup::communicator ()|, therefore, will return
MPI::COMM\_WORLD if the job is started directly with
\lstinline|mpirun| instead of with the MUSIC launcher.

Calling \lstinline|setup::done ()| will implicitly call the
\lstinline|runtime| object constructor.

During simulation, the application should repeatedly call
\lstinline|runtime::tick ()|.  This is typically done at each simulation
time step.

\section{Timing Considerations}

During a MUSIC simulation data is communicated between two connectors
by pairwise blocking communication.  Both sends and receives occur
within a \lstinline|tick ()| call.

\subsection{Global clock}

Connector pairs do not necessarily communicate at every tick.  It is
therefore important that both sender and receiver know when to
communicate.  In order to determine this deterministically MUSIC uses
an internal global integer clock.  Application specific tick intervals
are translated to an integral number of global clock time steps using
the MUSIC \emph{timebase}.  The timebase can be specified in the
configuration file using the variable name ``timebase''.  The default
value is 1 ns.

The reference implementation uses a 64-bit integer to represent the
global clock.

\begin{rationale}
  \emph{Discuss indeterminacy of floating-point arithmetic, in particular
    with regard to re-ordering of arithmetic operations by the compiler.}
\end{rationale}

\subsection{Time zone difference}

Minimal latency

\subsection{Communication schedule}

The order of calls to \lstinline|MPI::Send| and \lstinline|MPI::Receive| within
output and input connectors can be important.  Consider two
connections between the same pair of applications.  If application 1
sends on output connectors A and B in sequence, within the same tick,
while application 2 receives on the corresponding input connectors in
reverse order (B, A) there will be a dead-lock.

Such dead-lock:s are avoided by imposing a fixed pairwise
communication schedule.  The setup phase creates and sorts output and
input connectors into a vector according to this schedule.  This
vector is passed to the runtime object.  At each \lstinline|tick ()|, the
runtime object iterates through the vector, giving each connector an
opportunity to communicate.

\subsection{Initialization}

Before calling \lstinline|setup::done ()| at the end of the setup phase,
the user must initialize all data associated to output ports through
datamap:s.  During \lstinline|setup::done ()|, this data is transferred to
all input ports.  This is so that data can subsequently be correctly
interpolated.
\end{metatext}

\appendix

\chapter{C interface}

In the final MUSIC specification, this appendix will contain a
description of the C API to MUSIC.


\chapter{Specification file syntax}
\label{sec:specsyntax}

\newcommand{\nt}[1]{$<$#1$>$}

\begin{tabular}{lcl}
\nt{simulation spec}   & ::= & \{ \nt{application block} \} \\
\nt{application block} & ::= & \nt{newline} '[' \nt{application id} ']' \{ \nt{declaration}
\} \\
\nt{application id}    & ::= & \nt{symbol} \\
\nt{declaration}       & ::= & \nt{variable def} $|$ \nt{connection} \\
\nt{variable def}      & ::= & \nt{variable} '=' \nt{value} \\
\nt{variable}	       & ::= & \nt{symbol} \\
\nt{value} 	       & ::= & \nt{integer} $|$ \nt{float} $|$ \nt{string} \\
\nt{connection}	       & ::= & \nt{port id} \nt{direction} \nt{port id} [ \nt{width} ] \\
\nt{port id}	       & ::= & \nt{application id} '.' \nt{port} $|$
\nt{port} \\
\nt{port}	       & ::= & \nt{symbol} \\
\nt{direction}	       & ::= & $->$ $|$ $<-$ \\
\nt{width}	       & ::= & '[' \nt{integer} ']' \\
\end{tabular}

\printindex

\end{document}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% eval: (flyspell-mode 1)
%%% eval: (ispell-change-dictionary "american")
%%% eval: (flyspell-buffer)
%%% End: 
